# [BE] Fluent â€”  feedback bot another agent that shows up below watercooler prompt (copy to clipboard)

buildTag: repo
Priority: P1
Status: In progress

Switch voices

[https://console.cloud.google.com/speech/text-to-speech;input=Hey what's up;locale=en-US;voice=en-US-Casual-K;encoding=LINEAR16;speed=1;location=global?hl=en&project=padayon-ko-gemini](https://console.cloud.google.com/speech/text-to-speech;input=Hey%20what's%20up;locale=en-US;voice=en-US-Casual-K;encoding=LINEAR16;speed=1;location=global?hl=en&project=padayon-ko-gemini)

++ BUGS FIXED!! + pushed to 

[https://www.loom.com/share/fd9b513fb38d4680b7cf62e0b7912970?sid=8711a84c-a7a6-4a5d-a4a8-ef3b322e888c](https://www.loom.com/share/fd9b513fb38d4680b7cf62e0b7912970?sid=8711a84c-a7a6-4a5d-a4a8-ef3b322e888c)

```python
from flask import Flask, request, jsonify, render_template
import os
from speech_utils import transcribe_audio, synthesize_text
from gemini_utils import generate_ai_response
import uuid

app = Flask(__name__)

@app.route("/process_audio", methods=["POST"])
def process_audio():
    if "audio" not in request.files:
        return jsonify({"error": "No audio file provided"}), 400

    audio_file = request.files["audio"]
    mode = request.form.get("mode", "have a general conversation about")
    conversation_id = request.form.get("conversation_id", str(uuid.uuid4()))

    audio_data = audio_file.read()

    user_input = transcribe_audio(audio_data)

    if user_input is None:
        return (
            jsonify(
                {
                    "error": "Could not transcribe audio. Please try speaking more clearly or for a longer duration."
                }
            ),
            400,
        )

    ai_response = generate_ai_response(conversation_id, user_input, mode)
    audio_response = synthesize_text(ai_response)

    return jsonify(
        {
            "conversation_id": conversation_id,
            "user_input": user_input,
            "ai_response": ai_response,
            "audio_response": audio_response,
        }
    )

@app.route("/", methods=["GET"])
def index():
    return render_template("index.html")

if __name__ == "__main__":
    app.run(port=int(os.environ.get("PORT", 8080)), host="0.0.0.0", debug=True)

import os
from dotenv import load_dotenv
import google.generativeai as genai

# Load environment variables from .env file
load_dotenv()
gemini_api_key = os.getenv("GEMINI_API_KEY")

genai.configure(api_key=gemini_api_key)
model = genai.GenerativeModel("gemini-1.5-pro")

conversations = {}

def generate_ai_response(conversation_id, user_input, mode):
    if conversation_id not in conversations:
        conversations[conversation_id] = model.start_chat(history=[])

    chat = conversations[conversation_id]

    prompt = f"""You are an AI communication coach, designed to help users improve their verbal skills in various scenarios. The current mode is: {mode}.

Context: The user is practicing {mode} skills. They have just provided the following input: "{user_input}"

Your task is to:
1. Analyze the user's input based on the guidelines for {mode}.
2. Provide constructive feedback on their communication.
3. Offer suggestions for improvement.
4. Give an example of how the response could be enhanced.
5. Encourage the user to try again with the improvements in mind.

Guidelines for {mode}:

{get_mode_guidelines(mode)}

Please respond in a friendly, encouraging tone. Your response should be structured as follows:
1. Brief analysis of the user's input
2. Positive feedback on what was done well
3. Areas for improvement
4. An example of an enhanced response
5. Encouragement to try again

Remember to tailor your response specifically to the {mode} scenario and the user's input."""

    response = chat.send_message(prompt)
    return response.text

def get_mode_guidelines(mode):
    guidelines = {
        "debate": "Use the SEXI structure: State, Explain, provide an eXample, describe the Impact. Encourage logical arguments, use of evidence, and addressing counterpoints.",
        "storytelling": "Focus on the 5 C's: Characters, Conflict, Choice, Consequences, and Conclusion. Encourage vivid descriptions, emotional engagement, and a clear narrative arc.",
        "qa": "For asking questions: Use OPEN (Open-ended, Probing, Empathetic, Non-judgmental). For answering: Use STAR (Situation, Task, Action, Result). Encourage clarity, relevance, and depth in both questions and answers.",
        "explain": "Use the ELI5 method: Simplify complex ideas, use Analogies, Visualize concepts, and provide Examples. Encourage clear, concise explanations that avoid jargon and relate to familiar concepts.",
    }
    return guidelines.get(mode, "Focus on clear, engaging communication.")

from google.cloud import speech, texttospeech
import base64

speech_client = speech.SpeechClient()
tts_client = texttospeech.TextToSpeechClient()

def transcribe_audio(audio_content):
    audio = speech.RecognitionAudio(content=audio_content)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
        sample_rate_hertz=48000,
        language_code="en-PH",
    )

    try:
        response = speech_client.recognize(config=config, audio=audio)

        if not response.results:
            return None

        return response.results[0].alternatives[0].transcript
    except Exception as e:
        print(f"Transcription error: {str(e)}")
        return None

def synthesize_text(text):
    input_text = texttospeech.SynthesisInput(text=text)
    voice = texttospeech.VoiceSelectionParams(
        language_code="en-US",
        name="en-US-Standard-C",
        ssml_gender=texttospeech.SsmlVoiceGender.FEMALE,
    )
    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3
    )
    response = tts_client.synthesize_speech(
        input=input_text, voice=voice, audio_config=audio_config
    )
    return base64.b64encode(response.audio_content).decode("utf-8")

```